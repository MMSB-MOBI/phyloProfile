{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "836fa0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea762f2",
   "metadata": {},
   "source": [
    "# Binary matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07e24f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This script is able to build a coocurence matrix from a list of COG of an organism.\n",
    "It needs to take a csv file containing the list of the COG and the directory where the\n",
    "COG files are stored.\n",
    "It returns a numpy array.\n",
    "'''\n",
    "def iter_query_cog(query_orth):\n",
    "    with open(query_orth) as csvfile:\n",
    "        next(csvfile)\n",
    "        for l in csvfile:\n",
    "            buffer = l.split(';')\n",
    "            yield([buffer[4],buffer[5]])\n",
    "\n",
    "def cog_2_g_list(cog_id,cog_dir):\n",
    "    file_path = f'{cog_dir}/COG_{cog_id}.csv'\n",
    "    g_list = list()\n",
    "    with open(file_path) as csvfile:\n",
    "        next(csvfile)\n",
    "        for l in csvfile:\n",
    "            buffer = l.split(',')\n",
    "            strain = buffer[1]\n",
    "            g_list.append(strain)\n",
    "    return g_list\n",
    "\n",
    "def p_dict_builder(query_orth,cog_dir):\n",
    "    p_dict={}\n",
    "    i=0\n",
    "    for cog_id,p_name in iter_query_cog(query_orth):\n",
    "        g_list = cog_2_g_list(cog_id,cog_dir)\n",
    "        p_dict[p_name] = g_list\n",
    "        #i=i+1\n",
    "        #if i>9:\n",
    "            #break\n",
    "    return p_dict\n",
    "\n",
    "def index_setter(p_dict):\n",
    "    p_index = list()\n",
    "    g_index = set()\n",
    "    for p_name,g_list in p_dict.items():\n",
    "        p_index.append(p_name)\n",
    "        g_index.update(g_list)\n",
    "    g_index = list(g_index)\n",
    "    return p_index,g_index\n",
    "\n",
    "def set_M_values(M,m_index,g_name,p_name,value): \n",
    "    i = m_index[0].index(p_name) #protein index\n",
    "    j = m_index[1].index(g_name) #genome index\n",
    "    M[i,j] = value\n",
    "\n",
    "def matrix_builder(query_orth,cog_dir,value):\n",
    "    #generate a dictionnary of protein coocurences\n",
    "    p_dict=p_dict_builder(query_orth,cog_dir)\n",
    "    with open('p_dict.pkl', 'wb') as file:\n",
    "        pickle.dump(p_dict, file)\n",
    "    #generate the coocurences matrix index\n",
    "    m_index=index_setter(p_dict)\n",
    "    with open('m_index.pkl', 'wb') as file:\n",
    "        pickle.dump(m_index, file)\n",
    "    #generate the coocurences matrix\n",
    "    x = len(m_index[0])\n",
    "    y = len(m_index[1])\n",
    "    M = np.zeros((x,y))\n",
    "    for p_name,g_list in p_dict.items():\n",
    "        for g_name in g_list:\n",
    "            set_M_values(M,m_index,g_name,p_name,value)\n",
    "    with open('p_matrix.npy', 'wb') as f:\n",
    "        np.save(f, M)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8592ba29",
   "metadata": {},
   "source": [
    "To build a binary matrix use the matrix builder function.\n",
    "Feed it with a csv file listing the ortholog associated to your strain query \"query_orth\"\n",
    "and a directory containing all the COG groups \"cog_dir\".\n",
    "Set the value to \"1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70acca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#query_orth ='/Users/mdupuy/Documents/Stage/Pseudomonas_aeruginosa_PA7_119_ortholog_groups.csv'\n",
    "query_orth = 'Data/COG/Pseudomonas_aeruginosa_PA7_119_ortholog_groups.csv'\n",
    "cog_dir='Data/COG/All_COG_groups/'\n",
    "matrix_builder(query_orth,cog_dir,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06114b8b",
   "metadata": {},
   "source": [
    "# Score Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e04e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This script is able to build a coocurence matrix from a list of protein alignment score\n",
    "from sevaral organism against a query one.\n",
    "It needs to take txt files containing alignment score information.\n",
    "It returns a numpy array.\n",
    "'''\n",
    "def score_p_dict_builder(score_file_dir):\n",
    "    path = score_file_dir\n",
    "    dico_prot={}\n",
    "    for file in os.listdir(path):\n",
    "        dico_strain={}\n",
    "        protein = file.strip('_scores.txt')\n",
    "        file_path = f'{path}{file}'\n",
    "        with open(file_path,'r') as file:\n",
    "            for l in file:\n",
    "                buffer = l.split(',')\n",
    "                strain = buffer[2]\n",
    "                score = buffer[3].strip('\\n')\n",
    "                dico_strain[strain]=score\n",
    "        dico_prot[protein]=dico_strain\n",
    "    return(dico_prot)        \n",
    "\n",
    "def score_matrix_builder(score_file_dir,title):\n",
    "    if not os.path.isfile(f'p_dict_{title}.pkl'):\n",
    "        p_dict = score_p_dict_builder(score_file_dir)\n",
    "        with open(f'p_dict_{title}.pkl', 'wb') as file:\n",
    "            pickle.dump(p_dict, file)\n",
    "    else:\n",
    "        with open(f'p_dict_{title}.pkl', 'rb') as file:\n",
    "            p_dict = pickle.load(file)\n",
    "    if not os.path.isfile(f'm_index_{title}.pkl'):\n",
    "        m_index = index_setter(p_dict)\n",
    "        with open(f'm_index_{title}.pkl', 'wb') as file:\n",
    "            pickle.dump(m_index, file)\n",
    "    else:\n",
    "        with open(f'm_index_{title}.pkl', 'rb') as file:\n",
    "            m_index = pickle.load(file)\n",
    "    x = len(m_index[0])\n",
    "    y = len(m_index[1])\n",
    "    M = np.zeros((x,y))\n",
    "    for p_name,g_list in p_dict.items():\n",
    "            for g_name in g_list:\n",
    "                i = m_index[0].index(p_name) #protein index\n",
    "                j = m_index[1].index(g_name) #genome index\n",
    "                M[i,j] = p_dict[p_name][g_name]\n",
    "    #if not os.path.isfile(f'p_matrix_{title}.npy'):\n",
    "        #with open(f'p_matrix_{title}.npy', 'wb') as f:\n",
    "            #np.save(f, M)\n",
    "    #else:\n",
    "        #with open(f'p_matrix_{title}.npy', 'rb') as f:\n",
    "            #M = np.load(f,allow_pickle=True)\n",
    "    return(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cec48ab",
   "metadata": {},
   "source": [
    "To build a score matrix use the score_matrix_builder function.\n",
    "Feed it with directory containing all the alligment socre data \"score_file_dire\".\n",
    "Define a title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daa20854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 34s, sys: 4.69 s, total: 6min 39s\n",
      "Wall time: 7min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_file_dir = 'Data/Score/'\n",
    "score_matrix = score_matrix_builder(score_file_dir,'score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdf759f",
   "metadata": {},
   "source": [
    "# KEGG Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7007472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This script is able to build a pathway*protein matrix from a list of pathway.\n",
    "It needs to take txt files containing pathway information.\n",
    "It returns a numpy array.\n",
    "'''\n",
    "def iter_pathway(list_pathway):\n",
    "    with open(list_pathway) as file:\n",
    "        for l in file:\n",
    "            if l.strip():\n",
    "                buffer = l.split()\n",
    "                yield(buffer[0])\n",
    "            \n",
    "def pathway_dict_builder(list_pathway,path):\n",
    "    dico = {}\n",
    "    list_pathway = f'{path}{list_pathway}'\n",
    "    for pathway in iter_pathway(list_pathway):\n",
    "        file_path = f'{path}{pathway}.txt'\n",
    "        protein = []\n",
    "        with open(file_path) as file:\n",
    "            for l in file:\n",
    "                protein.append(l.strip('\\n'))\n",
    "        dico.setdefault(pathway,[]).extend(protein)  \n",
    "    return(dico)\n",
    "\n",
    "def kegg_matrix_builder(list_pathway,path):\n",
    "    pathway_dict = pathway_dict_builder(list_pathway,path)\n",
    "    m_index = index_setter(pathway_dict)\n",
    "    x = len(m_index[0])\n",
    "    y = len(m_index[1])\n",
    "    M = np.zeros((x,y))\n",
    "    for p_name,g_list in pathway_dict.items():\n",
    "        for g_name in g_list:\n",
    "            i = m_index[0].index(p_name) #protein index\n",
    "            j = m_index[1].index(g_name) #genome index\n",
    "            M[i,j] = 1\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e86da3c",
   "metadata": {},
   "source": [
    "To build a KEGG Matrix use the kegg_matrix_builder function. Feed it with a directory containing file describing pathway and the list of pathway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a03b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Data/KEGG/'\n",
    "list_pathway = 'List_126_KEGG_Path_PA7.txt'\n",
    "kegg_matrix = kegg_matrix_builder(list_pathway,path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5447cbf7",
   "metadata": {},
   "source": [
    "#  Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9bf41810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def svd(M,threshold):\n",
    "    '''\n",
    "    Apply the svd method to a score profile matrix to reduce it noise according to a\n",
    "    certain threshold\n",
    "    '''\n",
    "    M_xmax = np.amax(M,axis=1)\n",
    "    M_lnorm = np.divide(M.T,M_xmax).T\n",
    "    print(\"first normalisation\")\n",
    "    u, s, vh = np.linalg.svd(M_lnorm, full_matrices=False)\n",
    "    s[threshold:]=0.0\n",
    "    P = np.dot(u * s, vh)\n",
    "    print(\"svd\")\n",
    "    P_norm = np.linalg.norm(P,keepdims=True,axis=0)\n",
    "    P_u = np.divide(P,P_norm)\n",
    "    print(\"second normalisation\")\n",
    "    print(\"done\")\n",
    "    return P_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f624fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npp(M):\n",
    "    M=score_matrix\n",
    "    # corrige les valeurs à 0 pour prévenir les artefact\n",
    "    minval = np.min(M[np.nonzero(M)])\n",
    "    score_matrix[score_matrix==0]=minval\n",
    "    # normalisation par la taille\n",
    "    M_xmax = np.amax(M,axis=1)\n",
    "    M_lnorm = np.divide(M.T,M_xmax).T\n",
    "    # transformation monotonique\n",
    "    M_transf = np.reciprocal(M_lnorm)\n",
    "    # z-score\n",
    "    M_ymean = np.mean(M_transf,axis=0,keepdims=True)\n",
    "    M_ystd = np.std(M_transf,ddof=0,axis=0,keepdims=True)\n",
    "    M = np.divide(np.subtract(M,M_ymean),M_ystd)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c5ed57",
   "metadata": {},
   "source": [
    "# Distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25a59877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "def distance_matrix_builder(coocurencies_matrix,metric):\n",
    "    '''\n",
    "    the metric use to calculate the distance can be:\n",
    "    - 'hamming' for binary matrix, \n",
    "    - 'euclidean' and 'correlation' for score matrix\n",
    "    '''\n",
    "    if not os.path.isfile(f'{metric}_distance_matrix.pkl'):\n",
    "        distance = pdist(coocurencies_matrix, metric=metric)\n",
    "        distance_matrix = squareform(distance)\n",
    "        with open(f'{metric}_distance_matrix.pkl', 'wb') as f:\n",
    "            pickle.dump(distance_matrix,f)\n",
    "    else:\n",
    "        with open(f'{metric}_distance_matrix.pkl', 'rb') as file:\n",
    "            distance_matrix = pickle.load(file)\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62aeda6",
   "metadata": {},
   "source": [
    "# Test de précision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56af1ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "def df_intersect(df):\n",
    "    print('intersecting')\n",
    "    distance_matrix = df\n",
    "    observed_adjency = pd.read_pickle('data/observed_adjency_matrix.pkl')\n",
    "\n",
    "    d_ind = distance_matrix.index\n",
    "\n",
    "    o_ind = observed_adjency.index\n",
    "\n",
    "    ind = d_ind.intersection(o_ind)\n",
    "\n",
    "    distance_matrix = distance_matrix.reindex(index=ind, columns=ind)\n",
    "\n",
    "    #dico = distance_matrix.to_dict('split')\n",
    "    print('intersected')\n",
    "    return distance_matrix\n",
    "\n",
    "def get_couples(index_list):\n",
    "    for i in range(len(index_list)):\n",
    "        for j in range(i+1,len(index_list)):\n",
    "            yield((index_list[i],index_list[j]))\n",
    "\n",
    "def couple_sorter(df):\n",
    "    print('sorting')\n",
    "    couple_dist={}\n",
    "    dico = df.to_dict('split')\n",
    "    for couple in get_couples(dico['index']):\n",
    "        dist=df.loc[couple]\n",
    "        couple_dist.setdefault(dist,[]).append(couple)\n",
    "    couple_dist_ord = dict(sorted(couple_dist.items(),reverse=False))\n",
    "    #print(couple_dist_ord)\n",
    "    print('sorted')\n",
    "    return couple_dist_ord\n",
    "\n",
    "def courbe_rc(dico,shuffle):\n",
    "    print('ploting')\n",
    "    observed_adjency = pd.read_pickle('data/observed_adjency_matrix.pkl')\n",
    "    P_list = []\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    n = 1\n",
    "    value_list = list(dico.values())\n",
    "    if shuffle == True:\n",
    "        random.shuffle(value_list)\n",
    "    for value in value_list:\n",
    "        for couple in value:\n",
    "            if (observed_adjency.loc[couple[0],couple[1]]) == 1:\n",
    "                TP = TP+1\n",
    "            else:\n",
    "                FP = FP+1\n",
    "            n=n+1\n",
    "            if n==1000:\n",
    "                Precision = TP/(TP+FP)\n",
    "                P_list.append(Precision)\n",
    "                n = 1\n",
    "    print('ploted')\n",
    "    return P_list\n",
    "\n",
    "def benchmark(list_path):\n",
    "    dico_rc = {}\n",
    "    for path in list_path:\n",
    "        distance_matrix = pd.read_pickle(path)\n",
    "        intersect_matrix = df_intersect(distance_matrix)\n",
    "        couple_dist = couple_sorter(intersect_matrix)\n",
    "        rc_ord = courbe_rc(couple_dist, False)\n",
    "        dico_rc[path] = rc_ord\n",
    "    rc_rand = courbe_rc(couple_dist, True)\n",
    "    dico_rc['rand'] = rc_rand\n",
    "    return dico_rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8865188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = npp(score_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67496de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix = distance(M,'euclidean')\n",
    "import pandas as pd\n",
    "import pickle\n",
    "with open('m_index_score.pkl','rb') as file:\n",
    "    mynewlist = pickle.load(file)\n",
    "    p_list = mynewlist[0]\n",
    "df = pd.DataFrame(dist_matrix)\n",
    "df.index = p_list\n",
    "df.columns = p_list\n",
    "df.to_pickle('test_npp_eu.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
