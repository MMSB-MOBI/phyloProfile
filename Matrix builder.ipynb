{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "836fa0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "#from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "07e24f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This script is able to build a coocurence matrix from a list of COG of an organism.\n",
    "It needs to take a csv file containing the list of the COG and the directory where the\n",
    "COG files are stored.\n",
    "It returns a numpy array.\n",
    "'''\n",
    "def iter_query_cog(query_orth):\n",
    "    with open(query_orth) as csvfile:\n",
    "        next(csvfile)\n",
    "        for l in csvfile:\n",
    "            buffer = l.split(';')\n",
    "            yield([buffer[4],buffer[5]])\n",
    "\n",
    "def cog_2_g_list(cog_id,cog_dir):\n",
    "    file_path = f'{cog_dir}/COG_{cog_id}.csv'\n",
    "    g_list = list()\n",
    "    with open(file_path) as csvfile:\n",
    "        next(csvfile)\n",
    "        for l in csvfile:\n",
    "            buffer = l.split(',')\n",
    "            strain = buffer[1]\n",
    "            g_list.append(strain)\n",
    "    return g_list\n",
    "\n",
    "def p_dict_builder(query_orth,cog_dir):\n",
    "    p_dict={}\n",
    "    i=0\n",
    "    for cog_id,p_name in iter_query_cog(query_orth):\n",
    "        g_list = cog_2_g_list(cog_id,cog_dir)\n",
    "        p_dict[p_name] = g_list\n",
    "        #i=i+1\n",
    "        #if i>9:\n",
    "            #break\n",
    "    return p_dict\n",
    "\n",
    "def index_setter(p_dict):\n",
    "    p_index = list()\n",
    "    g_index = set()\n",
    "    for p_name,g_list in p_dict.items():\n",
    "        p_index.append(p_name)\n",
    "        g_index.update(g_list)\n",
    "    g_index = list(g_index)\n",
    "    return p_index,g_index\n",
    "\n",
    "def set_M_values(M,m_index,g_name,p_name,value): \n",
    "    i = m_index[0].index(p_name) #protein index\n",
    "    j = m_index[1].index(g_name) #genome index\n",
    "    M[i,j] = value\n",
    "\n",
    "def matrix_builder(query_orth,cog_dir,value):\n",
    "    #generate a dictionnary of protein coocurences\n",
    "    p_dict=p_dict_builder(query_orth,cog_dir)\n",
    "    with open('p_dict.pkl', 'wb') as file:\n",
    "        pickle.dump(p_dict, file)\n",
    "    #generate the coocurences matrix index\n",
    "    m_index=index_setter(p_dict)\n",
    "    with open('m_index.pkl', 'wb') as file:\n",
    "        pickle.dump(m_index, file)\n",
    "    #generate the coocurences matrix\n",
    "    x = len(m_index[0])\n",
    "    y = len(m_index[1])\n",
    "    M = np.zeros((x,y))\n",
    "    for p_name,g_list in p_dict.items():\n",
    "        for g_name in g_list:\n",
    "            set_M_values(M,m_index,g_name,p_name,value)\n",
    "    with open('p_matrix.npy', 'wb') as f:\n",
    "        np.save(f, M)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "23370fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_p_dict_builder(score_file_dir):\n",
    "    path = score_file_dir\n",
    "    dico_prot={}\n",
    "    for file in os.listdir(path):\n",
    "        dico_strain={}\n",
    "        protein = file.strip('_scores.txt')\n",
    "        file_path = f'{path}{file}'\n",
    "        with open(file_path,'r') as file:\n",
    "            for l in file:\n",
    "                buffer = l.split(',')\n",
    "                strain = buffer[2]\n",
    "                score = buffer[3].strip('\\n')\n",
    "                dico_strain[strain]=score\n",
    "        dico_prot[protein]=dico_strain\n",
    "    return(dico_prot)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3e04e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_matrix_builder(score_file_dir,title):\n",
    "    if not os.path.isfile(f'p_dict_{title}.pkl'):\n",
    "        p_dict = score_p_dict_builder(score_file_dir)\n",
    "        with open(f'p_dict_{title}.pkl', 'wb') as file:\n",
    "            pickle.dump(p_dict, file)\n",
    "    else:\n",
    "        with open(f'p_dict_{title}.pkl', 'rb') as file:\n",
    "            p_dict = pickle.load(file)\n",
    "    if not os.path.isfile(f'm_index_{title}.pkl'):\n",
    "        m_index = index_setter(p_dict)\n",
    "        with open(f'm_index_{title}.pkl', 'wb') as file:\n",
    "            pickle.dump(m_index, file)\n",
    "    else:\n",
    "        with open(f'm_index_{title}.pkl', 'rb') as file:\n",
    "            m_index = pickle.load(file)\n",
    "    x = len(m_index[0])\n",
    "    y = len(m_index[1])\n",
    "    M = np.zeros((x,y))\n",
    "    for p_name,g_list in p_dict.items():\n",
    "            for g_name in g_list:\n",
    "                i = m_index[0].index(p_name) #protein index\n",
    "                j = m_index[1].index(g_name) #genome index\n",
    "                M[i,j] = p_dict[p_name][g_name]\n",
    "    #if not os.path.isfile(f'p_matrix_{title}.npy'):\n",
    "        #with open(f'p_matrix_{title}.npy', 'wb') as f:\n",
    "            #np.save(f, M)\n",
    "    #else:\n",
    "        #with open(f'p_matrix_{title}.npy', 'rb') as f:\n",
    "            #M = np.load(f,allow_pickle=True)\n",
    "    return(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1c5c92",
   "metadata": {},
   "source": [
    "# KEGG Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "20c540fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_pathway(list_pathway):\n",
    "    with open(list_pathway) as file:\n",
    "        for l in file:\n",
    "            if l.strip():\n",
    "                buffer = l.split()\n",
    "                yield(buffer[0])\n",
    "            \n",
    "def pathway_dict_builder(list_pathway,path):\n",
    "    dico = {}\n",
    "    list_pathway = f'{path}{list_pathway}'\n",
    "    for pathway in iter_pathway(list_pathway):\n",
    "        file_path = f'{path}{pathway}.txt'\n",
    "        protein = []\n",
    "        with open(file_path) as file:\n",
    "            for l in file:\n",
    "                protein.append(l.strip('\\n'))\n",
    "        dico.setdefault(pathway,[]).extend(protein)  \n",
    "    return(dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8e0cb532",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/mdupuy/Documents/my_project/Pathways/'\n",
    "list_pathway = 'List_126_KEGG_Path_PA7.txt'\n",
    "pathway_dict = pathway_dict_builder(list_pathway,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "66c2ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_index = index_setter(pathway_dict)\n",
    "x = len(m_index[0])\n",
    "y = len(m_index[1])\n",
    "M = np.zeros((x,y))\n",
    "for p_name,g_list in pathway_dict.items():\n",
    "    for g_name in g_list:\n",
    "        i = m_index[0].index(p_name) #protein index\n",
    "        j = m_index[1].index(g_name) #genome index\n",
    "        M[i,j] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea762f2",
   "metadata": {},
   "source": [
    "# Binary matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70acca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "query_orth ='/Users/mdupuy/Documents/Stage/Pseudomonas_aeruginosa_PA7_119_ortholog_groups.csv'\n",
    "cog_dir='/Users/mdupuy/Documents/Stage/All_COG_groups/'\n",
    "matrix_builder(query_orth,cog_dir,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06114b8b",
   "metadata": {},
   "source": [
    "# Score Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "daa20854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 49s, sys: 540 ms, total: 2min 50s\n",
      "Wall time: 2min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_file_dir = '/Users/mdupuy/Documents/Stage/Parser/Scores/'\n",
    "score_matrix = score_matrix_builder(score_file_dir,'score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9bf41810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd(M,threshold):\n",
    "    '''\n",
    "    Apply the svd method to a score profile matrix to reduce it noise according to a\n",
    "    certain threshold\n",
    "    '''\n",
    "    M_xmax = np.amax(M,axis=1)\n",
    "    print(M_xmax)\n",
    "    M_lnorm = np.divide(M.T,M_xmax).T\n",
    "    #M_lnorm = np.nan_to_num(M_lnorm)\n",
    "    print(\"first normalisation\")\n",
    "    u, s, vh = np.linalg.svd(M_lnorm, full_matrices=False)\n",
    "    s[threshold:]=0.0\n",
    "    P = np.dot(u * s, vh)\n",
    "    print(P)\n",
    "    print(\"svd\")\n",
    "    P_norm = np.linalg.norm(P,keepdims=True,axis=0)\n",
    "    P_u = np.divide(P,P_norm)\n",
    "    print(\"second normalisation\")\n",
    "    print(\"done\")\n",
    "    return P_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f624fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npp(M):\n",
    "    M=score_matrix\n",
    "    # corrige les valeurs à 0 pour prévenir les artefact\n",
    "    minval = np.min(M[np.nonzero(M)])\n",
    "    score_matrix[score_matrix==0]=minval\n",
    "    # normalisation par la taille\n",
    "    M_xmax = np.amax(M,axis=1)\n",
    "    M_lnorm = np.divide(M.T,M_xmax).T\n",
    "    # transformation monotonique\n",
    "    M_transf = np.reciprocal(M_lnorm)\n",
    "    # z-score\n",
    "    M_ymean = np.mean(M_transf,axis=0,keepdims=True)\n",
    "    M_ystd = np.std(M_transf,ddof=0,axis=0,keepdims=True)\n",
    "    M = np.divide(np.subtract(M,M_ymean),M_ystd)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b3d96",
   "metadata": {},
   "source": [
    "# Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b5bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "def hamming(coocurencies_matrix):\n",
    "    hamming = pdist(coocurencies_matrix, metric='hamming')\n",
    "    distance_matrix = squareform(hamming)\n",
    "    with open('hd_matrix.pkl', 'wb') as f:\n",
    "        pickle.dump(distance_matrix,f)\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb8e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_M = hamming(M)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
